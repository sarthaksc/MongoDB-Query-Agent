ğŸ¤– AI Chatbot with LangChain + Streamlit

This is a conversational AI chatbot powered by LangChain, using either an LLM-only or Retrieval-Augmented Generation (RAG) approach. The app runs on a Streamlit interface for easy interaction and supports chat memory, and optionally vector store search using FAISS or MongoDB.

ğŸ—ï¸ Architecture Overview

            +-------------------------+
            |      Streamlit UI      |
            +-----------+-------------+
                        |
                        v
            +-------------------------+
            |  LangChain Chain (LLM)  |
            |  - ConversationChain    |
            |  - OR ConversationalRAG |
            +-----------+-------------+
                        |
            +-----------v-----------+
            |     Memory Module     | â† Maintains chat history
            +-----------------------+
                        |
            +-----------v-----------+
            |  (Optional) Retriever | â† FAISS / MongoDB vector DB
            +-----------------------+

            
LLM: Handles natural language generation.

Memory: Stores ongoing chat history using ConversationBufferMemory.

Retriever (Optional): Enhances answers by fetching relevant documents from a vector DB.

UI: Streamlit interface for easy deployment and interaction.

ğŸ› ï¸ Setup Instructions

1. Clone the Repository


git clone https://github.com/yourusername/your-repo.git
cd your-repo

2. Create and Activate a Virtual Environment

python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

3. Install Requirements

pip install -r requirements.txt

4. Set Up Environment Variables

Create a .env file in the project root with the following:

OPENAI_API_KEY=your_openai_api_key
MONGODB_URI=your_mongodb_connection_uri (optional)

ğŸ’¡ You can use any LLM provider (e.g., OpenAI, Cohere, Hugging Face) supported by LangChain.

ğŸš€ Running the Chatbot

streamlit run streamlit.py
This will launch the chatbot in your browser.

ğŸ§ª Sample Usage

Type a message like:

"What is LangChain?"

And get a smart answer based on the LLM (and optionally your documents).

ğŸ“‚ File Structure

â”œâ”€â”€ main.py               # Chatbot logic (LangChain chain)
â”œâ”€â”€ streamlit.py          # Streamlit UI
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env                  # Environment config
â”œâ”€â”€ README.md


ğŸ§  Tech Stack

Python 3.9+

Streamlit â€“ frontend UI

LangChain â€“ core chain logic

FAISS / MongoDB â€“ vector store (optional)

OpenAI / Hugging Face â€“ LLM provider

dotenv â€“ for secret config

ğŸ“Œ To Do

 Add vector store integration (e.g. FAISS or MongoDB Atlas Vector Search)

 Export chat history

 Add source document highlighting

ğŸ™Œ Acknowledgments

LangChain

Streamlit

OpenAI
